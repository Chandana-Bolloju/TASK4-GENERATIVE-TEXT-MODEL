# TASK4-GENERATIVE-TEXT-MODEL

*COMPANY*  : CODTECH IT SOLUTIONS

*NAME*   : CHANDANA BOLLOJU

*INTERN ID*  : CT04WT69

*DOMAIN*  : ARTIFICIAL INTELLIGENCE

*DURATION*  : 4 WEEKS

*MENTOR* : NEELA SANTOSH

This code implements a hybrid text generation system that combines two different approaches to natural language generation:

System Components
GPT-2 Integration

Utilizes the powerful GPT-2-medium model from Hugging Face's Transformers library

Provides high-quality, coherent text generation

Features temperature control for adjusting output randomness

Handles longer text sequences (up to 150 tokens by default)

Automatically initializes when first used

Custom LSTM Model

Implements a simpler neural network with Embedding, LSTM, and Dense layers

Trained on custom datasets provided by the user

Uses word-level tokenization and sequence prediction

Allows control over the number of words to generate

*OUTPUT*  :

![Image](https://github.com/user-attachments/assets/12022bb8-59d9-41a8-ba8b-aabbd5513a2f)

![Image](https://github.com/user-attachments/assets/1b7f0a27-7be0-4208-b4ee-515d019c63e1)

![Image](https://github.com/user-attachments/assets/28fb2c3a-f4d1-4b42-b106-02356a70d4db)

![Image](https://github.com/user-attachments/assets/234a5f7b-c2ea-457b-aa01-2653646e4986)
